{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "name": "14.04 대규모 데이터 학습.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/minicks/Datascience__school/blob/main/14_04_%EB%8C%80%EA%B7%9C%EB%AA%A8_%EB%8D%B0%EC%9D%B4%ED%84%B0_%ED%95%99%EC%8A%B5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRpBDqfaG-pf"
      },
      "source": [
        "# 대규모 데이터 학습"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aClvJsxvG-p4"
      },
      "source": [
        "대규모 데이터(big data)의 경우에는 메모리 등의 문제로 특정한 모형은 사용할 수 없는 경우가 많다. 이 때는 \n",
        "\n",
        "* 사전 확률분포를 설정할 수 있는 생성 모형\n",
        "* 시작 가중치를 설정할 수 있는 모형\n",
        "\n",
        "등을 이용하고 전체 데이터를 처리 가능한 작은 주각으로 나누어 학습을 시키는 점진적 학습 방법을 사용한다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAtY-J-LG-p7"
      },
      "source": [
        "from sklearn.datasets import fetch_covtype\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "covtype = fetch_covtype(shuffle=True, random_state=0)\n",
        "X_covtype = covtype.data\n",
        "y_covtype = covtype.target - 1\n",
        "classes = np.unique(y_covtype)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_covtype, y_covtype)\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "def read_Xy(start, end):\n",
        "    # 실무에서는 파일이나 데이터베이스에서 읽어온다.\n",
        "    idx = list(range(start, min(len(y_train) - 1, end)))\n",
        "    X = X_train[idx, :]\n",
        "    y = y_train[idx]\n",
        "    return X, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01004eDNG-p9"
      },
      "source": [
        "## SGD"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NrnU0DXG-p-"
      },
      "source": [
        "퍼셉트론 모형은 가중치를 계속 업데이트하므로 일부 데이터를 사용하여 구한 가중치를 다음 단계에서 초기 가중치로 사용할 수 있다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhLEYFUeG-p_",
        "outputId": "7f8b5d13-fe33-445a-e9aa-7dba13e14348"
      },
      "source": [
        "%%time\n",
        "\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "model = SGDClassifier(random_state=0)\n",
        "n_split = 10\n",
        "n_X = len(y_train) // n_split\n",
        "n_epoch = 10\n",
        "for epoch in range(n_epoch):\n",
        "    for n in range(n_split):\n",
        "        X, y = read_Xy(n * n_X, (n + 1) * n_X)\n",
        "        model.partial_fit(X, y, classes=classes)\n",
        "    accuracy_train = accuracy_score(y_train, model.predict(X_train))\n",
        "    accuracy_test = accuracy_score(y_test, model.predict(X_test))\n",
        "    print(\"epoch={:d} train acc={:5.3f} test acc={:5.3f}\".format(epoch, accuracy_train, accuracy_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch=0 train acc=0.707 test acc=0.707\n",
            "epoch=1 train acc=0.710 test acc=0.710\n",
            "epoch=2 train acc=0.711 test acc=0.710\n",
            "epoch=3 train acc=0.711 test acc=0.711\n",
            "epoch=4 train acc=0.711 test acc=0.711\n",
            "epoch=5 train acc=0.711 test acc=0.711\n",
            "epoch=6 train acc=0.711 test acc=0.711\n",
            "epoch=7 train acc=0.710 test acc=0.710\n",
            "epoch=8 train acc=0.711 test acc=0.711\n",
            "epoch=9 train acc=0.711 test acc=0.711\n",
            "CPU times: user 15.2 s, sys: 330 ms, total: 15.6 s\n",
            "Wall time: 9.21 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vOiaOBWG-qD"
      },
      "source": [
        "## 나이브베이즈 모형"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dA5WoocG-qE"
      },
      "source": [
        "나이브베이즈 모형과 같은 생성모형은 일부 데이터를 이용하여 구한 확률분포를 사전확률분포로 사용할 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mu6gfQR4G-qM",
        "outputId": "faaa2259-7b36-486d-cefe-974fbcb28071"
      },
      "source": [
        "%%time\n",
        "\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "model = BernoulliNB(alpha=0.1)\n",
        "\n",
        "n_split = 10\n",
        "n_X = len(y_train) // n_split\n",
        "for n in range(n_split):\n",
        "    X, y = read_Xy(n * n_X, (n + 1) * n_X)\n",
        "    model.partial_fit(X, y, classes=classes)\n",
        "    accuracy_train = accuracy_score(y_train, model.predict(X_train))\n",
        "    accuracy_test = accuracy_score(y_test, model.predict(X_test)) \n",
        "    print(\"n={:d} train accuracy={:5.3f} test accuracy={:5.3f}\".format(n, accuracy_train, accuracy_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "n=0 train accuracy=0.630 test accuracy=0.628\n",
            "n=1 train accuracy=0.630 test accuracy=0.629\n",
            "n=2 train accuracy=0.632 test accuracy=0.630\n",
            "n=3 train accuracy=0.633 test accuracy=0.632\n",
            "n=4 train accuracy=0.633 test accuracy=0.631\n",
            "n=5 train accuracy=0.632 test accuracy=0.631\n",
            "n=6 train accuracy=0.632 test accuracy=0.631\n",
            "n=7 train accuracy=0.632 test accuracy=0.630\n",
            "n=8 train accuracy=0.632 test accuracy=0.630\n",
            "n=9 train accuracy=0.632 test accuracy=0.630\n",
            "CPU times: user 10.1 s, sys: 920 ms, total: 11 s\n",
            "Wall time: 2.78 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBWSjDTSG-qO"
      },
      "source": [
        "## 그레디언트 부스팅"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2kFXmcPG-qO"
      },
      "source": [
        "그레디언트 부스팅에서는 초기 커미티 멤버로 일부 데이터를 사용하여 학습한 모형을 사용할 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EB8JlzwYG-qP",
        "outputId": "bc60ff10-6cd5-447c-a1ce-6dd0c70fca81"
      },
      "source": [
        "%%time\n",
        "\n",
        "from lightgbm import train, Dataset\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "params = {\n",
        "    'objective': 'multiclass',\n",
        "    \"num_class\": len(classes),\n",
        "    'learning_rate': 0.2,\n",
        "    'seed': 0,\n",
        "}\n",
        "\n",
        "n_split = 10\n",
        "n_X = len(y_train) // n_split\n",
        "num_tree = 10\n",
        "model = None\n",
        "for n in range(n_split):\n",
        "    X, y = read_Xy(n * n_X, (n + 1) * n_X)\n",
        "    model = train(params, init_model=model, train_set=Dataset(X, y),\n",
        "                  keep_training_booster=False, num_boost_round=num_tree)\n",
        "    accuracy_train = accuracy_score(y_train, np.argmax(model.predict(X_train), axis=1))\n",
        "    accuracy_test = accuracy_score(y_test, np.argmax(model.predict(X_test), axis=1)) \n",
        "    print(\"n={:d} train accuracy={:5.3f} test accuracy={:5.3f}\".format(n, accuracy_train, accuracy_test))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "n=0 train accuracy=0.769 test accuracy=0.767\n",
            "n=1 train accuracy=0.792 test accuracy=0.788\n",
            "n=2 train accuracy=0.806 test accuracy=0.802\n",
            "n=3 train accuracy=0.816 test accuracy=0.812\n",
            "n=4 train accuracy=0.812 test accuracy=0.807\n",
            "n=5 train accuracy=0.808 test accuracy=0.804\n",
            "n=6 train accuracy=0.805 test accuracy=0.800\n",
            "n=7 train accuracy=0.793 test accuracy=0.788\n",
            "n=8 train accuracy=0.795 test accuracy=0.790\n",
            "n=9 train accuracy=0.794 test accuracy=0.789\n",
            "CPU times: user 3min 17s, sys: 3.59 s, total: 3min 20s\n",
            "Wall time: 1min 3s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pkrz7UTQG-qR"
      },
      "source": [
        "## Random Forest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1e6RiO8G-qS"
      },
      "source": [
        "랜덤 포레스트와 같은 앙상블 모형에서는 일부 데이터를 사용한 모형을 개별 분류기로 사용할 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5l5HRuHG-qU",
        "outputId": "29533be3-9a8c-49b7-cbc9-051288c549bd"
      },
      "source": [
        "%%time\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "n_split = 10\n",
        "n_X = len(y_train) // n_split\n",
        "num_tree_ini = 10\n",
        "num_tree_step = 10\n",
        "model = RandomForestClassifier(n_estimators=num_tree_ini, warm_start=True)\n",
        "for n in range(n_split):\n",
        "    X, y = read_Xy(n * n_X, (n + 1) * n_X)\n",
        "    model.fit(X, y)\n",
        "    accuracy_train = accuracy_score(y_train, model.predict(X_train))\n",
        "    accuracy_test = accuracy_score(y_test, model.predict(X_test))\n",
        "    print(\"epoch={:d} train accuracy={:5.3f} test accuracy={:5.3f}\".format(n, accuracy_train, accuracy_test))\n",
        "    \n",
        "    model.n_estimators += num_tree_step"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch=0 train accuracy=0.868 test accuracy=0.855\n",
            "epoch=1 train accuracy=0.892 test accuracy=0.874\n",
            "epoch=2 train accuracy=0.898 test accuracy=0.880\n",
            "epoch=3 train accuracy=0.902 test accuracy=0.884\n",
            "epoch=4 train accuracy=0.904 test accuracy=0.885\n",
            "epoch=5 train accuracy=0.906 test accuracy=0.886\n",
            "epoch=6 train accuracy=0.906 test accuracy=0.887\n",
            "epoch=7 train accuracy=0.907 test accuracy=0.887\n",
            "epoch=8 train accuracy=0.907 test accuracy=0.888\n",
            "epoch=9 train accuracy=0.907 test accuracy=0.888\n",
            "CPU times: user 4min 46s, sys: 11.4 s, total: 4min 57s\n",
            "Wall time: 1min 42s\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}